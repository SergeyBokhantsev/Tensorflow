{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IZX3whF6eQ0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPooling2D, BatchNormalization, Add\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.regularizers import L2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from time import time\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [15, 10]\n",
        "\n",
        "# Set the seeds for reproducibility\n",
        "from numpy.random import seed\n",
        "from tensorflow.random import set_seed\n",
        "seed_value = 1234578790\n",
        "seed(seed_value)\n",
        "set_seed(seed_value)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Configuration section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62nbrRyzp_hH",
        "outputId": "75c915f1-543b-4d09-f1d5-d1f8e55de777"
      },
      "outputs": [],
      "source": [
        "# Environment type (local|colab)\n",
        "env = 'colab'\n",
        "\n",
        "# Run on Google Colab\n",
        "if (env == 'colab'):\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Terminal commands to copy and unzip dateset to a local storage\n",
        "    #cp -r /content/drive/MyDrive/ColabNotebooks/FaceUpscale/data.zip /content\n",
        "    #7z x data.zip\n",
        "\n",
        "    # Locations and batch size\n",
        "    train_folder = '/content/train'\n",
        "    test_folder = '/content/test'\n",
        "    train_batch_size = 64\n",
        "\n",
        "# Run Local\n",
        "if (env == 'local'):\n",
        "    # Locations and batch size\n",
        "    train_folder = '../data/train'\n",
        "    test_folder = '../data/test'\n",
        "    cache_folder = '../data/cache'\n",
        "    train_batch_size = 4\n",
        "\n",
        "# input image size\n",
        "x_img_size = 32\n",
        "\n",
        "# output image size\n",
        "y_img_size = 128\n",
        "# output image channels\n",
        "y_img_channels = 3"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data access section\n",
        "\n",
        "Contains methods for accessing and enumerating image datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7rOluPjp_hI"
      },
      "outputs": [],
      "source": [
        "# Cached image file pathes to avoid scan Filesystem on every epoch and to shuffle images\n",
        "train_files_list = []\n",
        "test_files_list = []\n",
        "\n",
        "# Recursively enumerates image files starting from given root folder\n",
        "def image_file_iterator(root):\n",
        "    for subdir, dirs, files in os.walk(root):        \n",
        "        for file in files:\n",
        "            if (file.endswith('.png')):\n",
        "                yield os.path.join(subdir, file)\n",
        "\n",
        "        for dir in dirs:\n",
        "            for file in image_file_iterator(dir):\n",
        "                yield os.path.join(subdir, file)\n",
        "\n",
        "# Shuffles and enumerates Train file pathes \n",
        "def train_files_shuffled_iterator():\n",
        "    global train_files_list\n",
        "    if (len(train_files_list) == 0):\n",
        "        train_files_list = list(image_file_iterator(train_folder))\n",
        "\n",
        "    np.random.shuffle(train_files_list)\n",
        "\n",
        "    for f in train_files_list:\n",
        "        yield f\n",
        "\n",
        "# Enumerates Test file pathes\n",
        "def test_files_iterator():\n",
        "    global test_files_list\n",
        "    if (len(test_files_list) == 0):\n",
        "        test_files_list = list(image_file_iterator(test_folder))\n",
        "\n",
        "    for f in test_files_list:\n",
        "        yield f\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image processing section\n",
        "\n",
        "Contains methods for image processing and augmentation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Scale image and normalize pixels to float 0..1 range\n",
        "def scale_and_normalize(img, size):\n",
        "    if (img.shape[0] != size or img.shape[1] != size):\n",
        "        img = cv2.resize(img, (size, size))\n",
        "    return img / 255\n",
        "\n",
        "# Rotates image for given degrees angle\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LANCZOS4)\n",
        "  return result\n",
        "\n",
        "# Horizontal flip\n",
        "def flip_image(img):\n",
        "    return cv2.flip(img, 1)\n",
        "\n",
        "# Loading images using given File path iterator, iterates image batches as a result\n",
        "# Note: When augmentation is enabled then every returning batch contains 4 times more images then requested via batch_size\n",
        "def data_iterator(file_iterator, batch_size, augmentation = False):\n",
        "    global file_cache_enabled\n",
        "    files_pending = True\n",
        "    while(files_pending):\n",
        "        # resulting batches\n",
        "        x_batch = []\n",
        "        y_batch = []\n",
        "\n",
        "        for _ in range(batch_size):\n",
        "            # get next file path\n",
        "            fpath = next(file_iterator, None) \n",
        "\n",
        "            # If file iterator provided a file path\n",
        "            if (fpath is not None):\n",
        "                # Load source image\n",
        "                src_img = cv2.imread(fpath)\n",
        "                src_img = cv2.cvtColor(src_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # Make normal XY\n",
        "                x_img = cv2.cvtColor(src_img, cv2.COLOR_RGB2GRAY)\n",
        "                x_img = scale_and_normalize(x_img, x_img_size)\n",
        "                y_img = scale_and_normalize(src_img, y_img_size)\n",
        "                x_batch.append(x_img)\n",
        "                y_batch.append(y_img)\n",
        "                    \n",
        "                if (not augmentation):\n",
        "                    continue\n",
        "\n",
        "                # Flipped XY\n",
        "                x_img = flip_image(x_img)\n",
        "                y_img = flip_image(y_img)\n",
        "                x_batch.append(x_img)\n",
        "                y_batch.append(y_img)\n",
        "\n",
        "                # Rotated XY\n",
        "                angle = np.random.randint(10,20)                    \n",
        "                y_img = rotate_image(src_img, angle)\n",
        "                x_img = cv2.cvtColor(y_img, cv2.COLOR_RGB2GRAY)\n",
        "                x_img = scale_and_normalize(x_img, x_img_size)\n",
        "                y_img = scale_and_normalize(y_img, y_img_size)\n",
        "                x_batch.append(x_img)\n",
        "                y_batch.append(y_img)\n",
        "\n",
        "                # Rotated flipped XY\n",
        "                x_img = flip_image(x_img)\n",
        "                y_img = flip_image(y_img)\n",
        "                x_batch.append(x_img)\n",
        "                y_batch.append(y_img)\n",
        "\n",
        "            # If file's iterator end reached\n",
        "            else:\n",
        "                files_pending = False\n",
        "                break\n",
        "        \n",
        "        if len(x_batch) > 0:\n",
        "            yield np.array(x_batch), np.array(y_batch)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tests for data iterators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XydHB4mcp_hI",
        "outputId": "70be77fa-9c6a-4f26-caf0-5dd7d184fbc0"
      },
      "outputs": [],
      "source": [
        "# Let's test file iterators and see the number of files\n",
        "train_set_len = sum(1 for _ in image_file_iterator(train_folder))\n",
        "test_set_len = sum(1 for _ in image_file_iterator(test_folder))\n",
        "\n",
        "print('Train files:', train_set_len)\n",
        "print('Test files:', test_set_len)\n",
        "\n",
        "# Also do a smoke test for datagen \n",
        "# for 1000 test images we expecting 1000 batches (when batch_size = 1)\n",
        "if (sum(1 for _ in data_iterator(test_files_iterator(), batch_size=1)) == test_set_len):\n",
        "    print('data_iterator OK')\n",
        "else:\n",
        "    print('data_iterator failure!')\n",
        "\n",
        "# for 1000 test images we expecting 500 batches (when batch_size = 2)\n",
        "if (sum(1 for _ in data_iterator(test_files_iterator(), 2)) == test_set_len / 2):\n",
        "    print('data_iterator OK')\n",
        "else:\n",
        "    print('data_iterator failure!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "mQuLFpLKp_hI",
        "outputId": "e50d35cf-4dbf-443f-d663-bb100848abf8"
      },
      "outputs": [],
      "source": [
        "# test data_iterator for Train set (without augmentation)\n",
        "# get a single batch of 10 images\n",
        "batch = next(data_iterator(train_files_shuffled_iterator(), 10))\n",
        "\n",
        "x_train_batch = batch[0]\n",
        "y_train_batch = batch[1]\n",
        "\n",
        "# Show X\n",
        "for ii in range(x_train_batch.shape[0]):\n",
        "    plt.subplot(3,5,ii+1), plt.imshow(x_train_batch[ii], cmap = 'gray'), plt.title(ii)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "zMUhFfZXp_hJ",
        "outputId": "d56cd4e6-662b-45eb-eb01-0864ec40fda9"
      },
      "outputs": [],
      "source": [
        "# Show Y\n",
        "for ii in range(y_train_batch.shape[0]):\n",
        "    plt.subplot(3,5,ii+1), plt.imshow(y_train_batch[ii]), plt.title(ii)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deep learning section\n",
        "\n",
        "I'm using Residual Dense Blocks + Pixel Shuffle Super Resolution network model with custom loss function and PSNR metric\n",
        "\n",
        "The overal network structure is:\n",
        "[INPUT]-[CONV]-[CONV]-[RDB]-[CONV]-[RDB]-[CONV]-[PIXEL-SHUFFLE]-[OUTPUT]\n",
        "\n",
        "where [RDB] is a Residual Dense Blocks part consisting of a number of interconnected [CONV] layers\n",
        "and [PIXEL-SHUFFLE] is a special layer that converts a number of input layers to a WxH layer  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_iPVDd8p_hJ"
      },
      "outputs": [],
      "source": [
        "# Residual Dense Blocks function\n",
        "def rdb_block(inputs, layers_count):\n",
        "    # get number of input channels\n",
        "    channels = inputs.get_shape()[-1]\n",
        "    # initialize outputs list\n",
        "    outputs = [inputs]\n",
        "    \n",
        "    # common Conv2D args\n",
        "    conv_args = {\n",
        "        \"activation\": \"relu\",\n",
        "        \"kernel_initializer\": \"Orthogonal\",\n",
        "        \"padding\": \"same\",\n",
        "    }\n",
        "\n",
        "    # Make Residual Dense Block\n",
        "    for _ in range(layers_count):\n",
        "        concatenation = tf.concat(outputs, axis=-1)\n",
        "        net = Conv2D(channels, 3, **conv_args)(concatenation)\n",
        "        outputs.append(net)\n",
        "\n",
        "    # Make final resulting net\n",
        "    final_concatenation = tf.concat(outputs, axis=-1)\n",
        "    final_net = Conv2D(channels, 1, **conv_args)(final_concatenation)\n",
        "\n",
        "    # Add input net and final output net (RDB)\n",
        "    final_net = Add()([final_net, inputs])\n",
        "\n",
        "    return final_net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eGtiMJWp_hJ",
        "outputId": "adb494b2-475b-47ca-d329-1ee097e9cc98"
      },
      "outputs": [],
      "source": [
        "if (env == 'local'):\n",
        "    # workaround for some unclear error\n",
        "    os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "# Common args we will use for all Conv2D layers \n",
        "conv_args = {\n",
        "        \"activation\": \"relu\",\n",
        "        \"kernel_initializer\": \"Orthogonal\",\n",
        "        \"padding\": \"same\",\n",
        "    }\n",
        "\n",
        "# We need to know Y to X scale to initialize a pixel-shuffle layer properly\n",
        "scale_ratio = int(y_img_size / x_img_size)\n",
        "print('Scale ratio: ', scale_ratio)\n",
        "\n",
        "inputs = Input(shape=(x_img_size, x_img_size, 1))\n",
        "net = Conv2D(80, 5, **conv_args)(inputs)\n",
        "net = Conv2D(80, 3, **conv_args)(net)\n",
        "# Adding RDB Block\n",
        "net = rdb_block(net, layers_count=8)\n",
        "net = Conv2D(48, 3, **conv_args)(net)\n",
        "# Adding other RDB Block\n",
        "net = rdb_block(net, layers_count=8)\n",
        "net = Conv2D(48, 3, **conv_args)(net)\n",
        "# Pixel-shuffling\n",
        "net = Conv2D(y_img_channels * (scale_ratio ** 2), 3, **conv_args)(net)\n",
        "# Output\n",
        "outputs = tf.nn.depth_to_space(net, scale_ratio)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train infrastructure section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhr1lplCp_hJ"
      },
      "outputs": [],
      "source": [
        "# Peak Signal to Noise Ratio function\n",
        "def psnr(orig, pred):\n",
        "    # cast the target images to integer\n",
        "\torig = orig * 255.0\n",
        "\torig = tf.cast(orig, tf.uint8)\n",
        "\torig = tf.clip_by_value(orig, 0, 255)\n",
        "\t# cast the predicted images to integer\n",
        "\tpred = pred * 255.0\n",
        "\tpred = tf.cast(pred, tf.uint8)\n",
        "\tpred = tf.clip_by_value(pred, 0, 255)\n",
        "\t# return the psnr\n",
        "\treturn tf.image.psnr(orig, pred, max_val=255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLPjvz5D8exs"
      },
      "outputs": [],
      "source": [
        "# Wrapper for the data_iterator from Data Access section \n",
        "# makes data_iterator infinite\n",
        "def datagen(batch_size):\n",
        "    iterator = data_iterator(train_files_shuffled_iterator(), batch_size, augmentation=True)\n",
        "    while(True):\n",
        "        result = next(iterator, None)\n",
        "\n",
        "        if (result is None):\n",
        "            iterator = data_iterator(train_files_shuffled_iterator(), batch_size)\n",
        "        else:\n",
        "            yield result\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "jcvpiRFBs7v9",
        "outputId": "96d2b942-0ab1-41b7-8317-6a40ebec4e50"
      },
      "outputs": [],
      "source": [
        "# Test the train datagen: get a single batch with batch_size=1 to check augmentation\n",
        "def do_test_datagen():\n",
        "    # Create datagenerator\n",
        "    dg = datagen(1)\n",
        "    img_n = 0\n",
        "\n",
        "    # get a batch\n",
        "    x_batch, y_batch = next(dg)\n",
        "\n",
        "    # Show all the images returned in a batch: there must be one original XY pair and three augmentation versions \n",
        "    for ii in range(x_batch.shape[0]):\n",
        "        img_n += 1\n",
        "        plt.subplot(5,6,img_n), plt.imshow(x_batch[ii], cmap = 'gray'), plt.title('X')\n",
        "        img_n += 1\n",
        "        plt.subplot(5,6,img_n), plt.imshow(y_batch[ii], cmap = 'gray'), plt.title('Y')\n",
        "           \n",
        "do_test_datagen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EhHfAqk4A09"
      },
      "outputs": [],
      "source": [
        "# Loss function class\n",
        "# The idea is to calculate MSE differently for image center part and image side parts\n",
        "# because 99% of the train set has face in a entral part of image\n",
        "# and we want our network to not to confuse by image background while training    \n",
        "class CenterImagePriorityLoss(tf.keras.losses.Loss):\n",
        "\n",
        "  # Defines the multiplication of a center MSE over a total MSE \n",
        "  cmr = 1\n",
        "  # Defines the center area ratio: example car=0.5 means the center area size will be 1/2 of the image H and W  \n",
        "  car = 0.5\n",
        "\n",
        "  def __init__(self, center_multiplication_ratio, center_area_ratio):\n",
        "    super().__init__()\n",
        "    self.cmr = center_multiplication_ratio\n",
        "    self.car = center_area_ratio\n",
        "  \n",
        "  def call(self, y_true, y_pred):\n",
        "    \n",
        "    # Calculate MSE of the full image\n",
        "    full_img_mse = tf.reduce_mean(tf.square(y_pred-y_true))\n",
        "\n",
        "    # Calculate MSE of center area\n",
        "    margin = int(y_img_size * (1.0-self.car) / 2)\n",
        "    y_true = y_true[:,margin:y_img_size-margin, margin:y_img_size-margin,:]\n",
        "    y_pred = y_pred[:,margin:y_img_size-margin, margin:y_img_size-margin,:]\n",
        "    center_img_mse = tf.reduce_mean(tf.square(y_pred-y_true))\n",
        "\n",
        "    # Calculate final MSE \n",
        "    return (full_img_mse + center_img_mse*(self.cmr-1)) / self.cmr"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make some basic tests for the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tf339FG4A09",
        "outputId": "ad640372-5792-42c9-c9d9-f5d33398bc70"
      },
      "outputs": [],
      "source": [
        "sut = CenterImagePriorityLoss(3, 0.7)\n",
        "\n",
        "mock_img1 = np.random.random((1, y_img_size, y_img_size, 3))\n",
        "mock_img2 = np.random.random((1, y_img_size, y_img_size, 3))\n",
        "\n",
        "print('Same images compare (loss must be 0)', sut.call(mock_img1, mock_img1))\n",
        "print('Another same images (loss must be 0)', sut.call(mock_img2, mock_img2))\n",
        "print('Different images compare (loss must be > 0)', sut.call(mock_img1, mock_img2))\n",
        "\n",
        "# create two CIPL with different center area koefs\n",
        "sut03 = CenterImagePriorityLoss(3, 0.3)\n",
        "sut07 = CenterImagePriorityLoss(3, 0.7)\n",
        "\n",
        "# they must return different loss for a same image pairs\n",
        "print('Must be different:')\n",
        "print(sut03.call(mock_img1, mock_img2))\n",
        "print(sut07.call(mock_img1, mock_img2))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHoOeq9op_hK",
        "outputId": "0481bfe8-8861-4376-cdbf-a44328571cfe"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "steps_per_epoch = train_set_len / train_batch_size + 1\n",
        "\n",
        "# prepare validation set (no need to read the set from disk every epoch)\n",
        "x_test, y_test = next(data_iterator(test_files_iterator(), test_set_len))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss=CenterImagePriorityLoss(3, 0.65), optimizer=Adam(learning_rate=0.001), metrics=psnr)\n",
        "\n",
        "# configure early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='min', restore_best_weights=True)\n",
        "\n",
        "# train\n",
        "history = model.fit(datagen(train_batch_size), steps_per_epoch=steps_per_epoch, epochs=epochs, validation_data=(x_test, y_test), callbacks=[early_stopping])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Draw training history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show training history (this cell is complete, nothing to implement here :-) )\n",
        "h = history.history\n",
        "epochs = range(len(h['loss']))\n",
        "\n",
        "plt.subplot(121), plt.plot(epochs, h['loss'], '.-', epochs, h['val_loss'], '.-')\n",
        "plt.grid(True), plt.xlabel('epochs'), plt.ylabel('loss')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.subplot(122), plt.plot(epochs, h['psnr'], '.-',\n",
        "                           epochs, h['val_psnr'], '.-')\n",
        "plt.grid(True), plt.xlabel('epochs'), plt.ylabel('PSNR')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "\n",
        "print('Train PSNR     ', h['psnr'][-1])\n",
        "print('Validation PSNR', h['val_psnr'][-1])    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predict and visualize (Input, Input upscaled by OpenCV, Predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c1R0oKVRp_hK",
        "outputId": "15fd0947-8a53-4104-fbcb-829140b360db"
      },
      "outputs": [],
      "source": [
        "# prepare test images\n",
        "test_range = 20\n",
        "di = data_iterator(test_files_iterator(), test_range)\n",
        "batch = next(di)\n",
        "x_test = batch[0]\n",
        "\n",
        "# predict\n",
        "y_test = model.predict(x_test)\n",
        "\n",
        "# visualize\n",
        "for ii in range(test_range):\n",
        "    f, axarr = plt.subplots(1,3)\n",
        "    axarr[0].imshow(x_test[ii], cmap='gray')\n",
        "    axarr[1].imshow(cv2.resize(x_test[ii], (y_img_size, y_img_size), interpolation=cv2.INTER_LANCZOS4), cmap='gray')\n",
        "    axarr[2].imshow(np.array(y_test[ii]))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save the model if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaMK4vcAaWy2",
        "outputId": "4dc1b8d4-37b5-482d-e6af-090c7df3f03f"
      },
      "outputs": [],
      "source": [
        "# model.save('/content/drive/MyDrive/ColabNotebooks/FaceUpscale/model')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 ('cv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b6c733efa17d1e9f6237ee30a57df6101a3b9e76b9636c4b405ae372ec99fb54"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
